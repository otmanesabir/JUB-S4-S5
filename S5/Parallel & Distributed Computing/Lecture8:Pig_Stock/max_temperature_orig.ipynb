{"cells":[{"cell_type":"code","metadata":{"tags":[],"cell_id":"00000-5ecfde59-5d5e-4534-b170-da0e4f2b5ace","output_cleared":false,"source_hash":"66f71ed9","execution_millis":36280,"execution_start":1605524401394},"source":"%%bash\n$HADOOP_HOME/sbin/start-dfs.sh\n$HADOOP_HOME/sbin/start-yarn.sh\n$HADOOP_HOME/bin/mapred --daemon start historyserver","outputs":[{"name":"stdout","text":"Starting namenodes on [localhost]\nStarting datanodes\nStarting secondary namenodes [p-fb00a143-bee8-437f-b51a-dc92d20f1763]\nStarting resourcemanager\nStarting nodemanagers\n","output_type":"stream"}],"execution_count":null},{"cell_type":"code","metadata":{"tags":[],"cell_id":"00001-647ef45d-ab0e-4a7f-95a3-35d4df0842aa","output_cleared":false,"source_hash":"459438de","execution_millis":1,"execution_start":1605524437674},"source":"%%file sample_orig.txt\n0067011990999991950051507004+68750+023550FM-12+038299999V0203301N00671220001CN9999999N9+00001+99999999999\n0043011990999991950051512004+68750+023550FM-12+038299999V0203201N00671220001CN9999999N9+00221+99999999999\n0043011990999991950051518004+68750+023550FM-12+038299999V0203201N00261220001CN9999999N9-00111+99999999999\n0043012650999991949032412004+62300+010750FM-12+048599999V0202701N00461220001CN0500001N9+01111+99999999999\n0043012650999991949032418004+62300+010750FM-12+048599999V0202701N00461220001CN0500001N9+00781+99999999999","outputs":[{"name":"stdout","text":"Overwriting sample_orig.txt\n","output_type":"stream"}],"execution_count":null},{"cell_type":"code","metadata":{"tags":[],"cell_id":"00001-d20431cd-2eb1-4d20-a69d-858fde120a78","output_cleared":false,"source_hash":"70965ab6","execution_millis":12543,"execution_start":1605524437675},"source":"! $HADOOP_HOME/bin/hdfs dfs -put sample_orig.txt .","outputs":[{"name":"stdout","text":"put: `sample_orig.txt': File exists\r\n","output_type":"stream"}],"execution_count":null},{"cell_type":"markdown","source":"The below cell contains the original maximum temperature code from the lecture. Modify it, such that it can equally parse \"smple_orig.txt\", i.e. the data in its original format as known from the MapReduce example.","metadata":{"tags":[],"cell_id":"00003-6b626a58-d0bf-40cc-b714-17bebda2edc1","output_cleared":false}},{"cell_type":"code","metadata":{"tags":[],"cell_id":"00001-6679f9eb-4e83-4b53-a22f-078fc6412cd8","output_cleared":false,"source_hash":"6c0720b0","execution_millis":50,"execution_start":1605524450229},"source":"%%file max_temp_orig.pig\nrecords = LOAD 'sample_orig.txt' USING org.apache.pig.piggybank.storage.FixedWidthLoader('16-19,88-92,93') AS (year:chararray, temp:int, q:int);\nfiltered = FILTER records BY temp != 9999 AND q IN (0,1,4,5,9);\ngrouped = GROUP filtered BY year;\nmax_temp = FOREACH grouped GENERATE group, MAX(filtered.temp);\nSTORE max_temp INTO 'output';","outputs":[{"name":"stdout","text":"Overwriting max_temp_orig.pig\n","output_type":"stream"}],"execution_count":null},{"cell_type":"code","metadata":{"tags":[],"cell_id":"00002-6a73e47e-7814-42fe-975c-ffafbeb6a5b9","output_cleared":false,"source_hash":"92f7c49b","execution_millis":50335,"execution_start":1605524450279},"source":"! $PIG_HOME/bin/pig max_temp_orig.pig","outputs":[{"name":"stdout","text":"2020-11-16 11:00:55,076 INFO pig.ExecTypeProvider: Trying ExecType : LOCAL\n2020-11-16 11:00:55,077 INFO pig.ExecTypeProvider: Trying ExecType : MAPREDUCE\n2020-11-16 11:00:55,077 INFO pig.ExecTypeProvider: Picked MAPREDUCE as the ExecType\n2020-11-16 11:00:55,137 [main] INFO  org.apache.pig.Main - Apache Pig version 0.17.0 (r1797386) compiled Jun 02 2017, 15:41:58\n2020-11-16 11:00:55,137 [main] INFO  org.apache.pig.Main - Logging error messages to: /home/jovyan/work/pig_1605524455126.log\n2020-11-16 11:00:55,758 [main] INFO  org.apache.pig.impl.util.Utils - Default bootup file /home/jovyan/.pigbootup not found\n2020-11-16 11:00:55,886 [main] INFO  org.apache.hadoop.conf.Configuration.deprecation - mapred.job.tracker is deprecated. Instead, use mapreduce.jobtracker.address\n2020-11-16 11:00:55,886 [main] INFO  org.apache.pig.backend.hadoop.executionengine.HExecutionEngine - Connecting to hadoop file system at: hdfs://localhost:9000\n2020-11-16 11:00:56,661 [main] INFO  org.apache.pig.PigServer - Pig Script ID for the session: PIG-max_temp_orig.pig-ac742124-93e2-4597-b8c4-edb47731c4d0\n2020-11-16 11:00:56,662 [main] WARN  org.apache.pig.PigServer - ATS is disabled since yarn.timeline-service.enabled set to false\n2020-11-16 11:00:57,734 [main] INFO  org.apache.hadoop.conf.Configuration.deprecation - mapred.textoutputformat.separator is deprecated. Instead, use mapreduce.output.textoutputformat.separator\n2020-11-16 11:00:57,775 [main] INFO  org.apache.pig.tools.pigstats.ScriptState - Pig features used in the script: GROUP_BY,FILTER\n2020-11-16 11:00:57,821 [main] INFO  org.apache.pig.data.SchemaTupleBackend - Key [pig.schematuple] was not set... will not generate code.\n2020-11-16 11:00:57,856 [main] INFO  org.apache.pig.newplan.logical.optimizer.LogicalPlanOptimizer - {RULES_ENABLED=[AddForEach, ColumnMapKeyPrune, ConstantCalculator, GroupByConstParallelSetter, LimitOptimizer, LoadTypeCastInserter, MergeFilter, MergeForEach, NestedLimitOptimizer, PartitionFilterOptimizer, PredicatePushdownOptimizer, PushDownForEachFlatten, PushUpFilter, SplitFilter, StreamTypeCastInserter]}\n2020-11-16 11:00:57,959 [main] INFO  org.apache.pig.impl.util.SpillableMemoryManager - Selected heap (G1 Old Gen) of size 1048576000 to monitor. collectionUsageThreshold = 734003200, usageThreshold = 734003200\n2020-11-16 11:00:58,098 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MRCompiler - File concatenation threshold: 100 optimistic? false\n2020-11-16 11:00:58,113 [main] INFO  org.apache.pig.backend.hadoop.executionengine.util.CombinerOptimizerUtil - Choosing to move algebraic foreach to combiner\n2020-11-16 11:00:58,140 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MultiQueryOptimizer - MR plan size before optimization: 1\n2020-11-16 11:00:58,140 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MultiQueryOptimizer - MR plan size after optimization: 1\n2020-11-16 11:00:58,296 [main] INFO  org.apache.hadoop.yarn.client.DefaultNoHARMFailoverProxyProvider - Connecting to ResourceManager at /0.0.0.0:8032\n2020-11-16 11:00:58,550 [main] INFO  org.apache.hadoop.conf.Configuration.deprecation - yarn.resourcemanager.system-metrics-publisher.enabled is deprecated. Instead, use yarn.system-metrics-publisher.enabled\n2020-11-16 11:00:58,579 [main] INFO  org.apache.pig.tools.pigstats.mapreduce.MRScriptState - Pig script settings are added to the job\n2020-11-16 11:00:58,588 [main] INFO  org.apache.hadoop.conf.Configuration.deprecation - mapred.job.reduce.markreset.buffer.percent is deprecated. Instead, use mapreduce.reduce.markreset.buffer.percent\n2020-11-16 11:00:58,593 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.JobControlCompiler - mapred.job.reduce.markreset.buffer.percent is not set, set to default 0.3\n2020-11-16 11:00:58,595 [main] INFO  org.apache.hadoop.conf.Configuration.deprecation - mapred.output.compress is deprecated. Instead, use mapreduce.output.fileoutputformat.compress\n2020-11-16 11:00:58,601 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.JobControlCompiler - Reduce phase detected, estimating # of required reducers.\n2020-11-16 11:00:58,602 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.JobControlCompiler - Using reducer estimator: org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.InputSizeReducerEstimator\n2020-11-16 11:00:58,690 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.InputSizeReducerEstimator - BytesPerReducer=1000000000 maxReducers=999 totalInputFileSize=530\n2020-11-16 11:00:58,690 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.JobControlCompiler - Setting Parallelism to 1\n2020-11-16 11:00:58,690 [main] INFO  org.apache.hadoop.conf.Configuration.deprecation - mapred.reduce.tasks is deprecated. Instead, use mapreduce.job.reduces\n2020-11-16 11:00:58,690 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.JobControlCompiler - This job cannot be converted run in-process\n2020-11-16 11:00:58,828 [main] INFO  org.apache.hadoop.conf.Configuration.deprecation - mapred.submit.replication is deprecated. Instead, use mapreduce.client.submit.file.replication\n2020-11-16 11:00:59,781 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.JobControlCompiler - Added jar file:/home/jovyan/pig-0.17.0/lib/piggybank.jar to DistributedCache through /tmp/temp-874437959/tmp-949154909/piggybank.jar\n2020-11-16 11:00:59,989 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.JobControlCompiler - Added jar file:/home/jovyan/pig-0.17.0/pig-0.17.0-core-h2.jar to DistributedCache through /tmp/temp-874437959/tmp617277713/pig-0.17.0-core-h2.jar\n2020-11-16 11:01:00,040 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.JobControlCompiler - Added jar file:/home/jovyan/pig-0.17.0/lib/automaton-1.11-8.jar to DistributedCache through /tmp/temp-874437959/tmp850649805/automaton-1.11-8.jar\n2020-11-16 11:01:00,107 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.JobControlCompiler - Added jar file:/home/jovyan/pig-0.17.0/lib/antlr-runtime-3.4.jar to DistributedCache through /tmp/temp-874437959/tmp-1723324470/antlr-runtime-3.4.jar\n2020-11-16 11:01:00,158 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.JobControlCompiler - Added jar file:/home/jovyan/pig-0.17.0/lib/joda-time-2.9.3.jar to DistributedCache through /tmp/temp-874437959/tmp1600481443/joda-time-2.9.3.jar\n2020-11-16 11:01:00,184 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.JobControlCompiler - Setting up single store job\n2020-11-16 11:01:00,189 [main] INFO  org.apache.pig.data.SchemaTupleFrontend - Key [pig.schematuple] is false, will not generate code.\n2020-11-16 11:01:00,189 [main] INFO  org.apache.pig.data.SchemaTupleFrontend - Starting process to move generated code to distributed cacche\n2020-11-16 11:01:00,190 [main] INFO  org.apache.pig.data.SchemaTupleFrontend - Setting key [pig.schematuple.classes] with classes to deserialize []\n2020-11-16 11:01:00,460 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MapReduceLauncher - 1 map-reduce job(s) waiting for submission.\n2020-11-16 11:01:00,538 [JobControl] INFO  org.apache.hadoop.yarn.client.DefaultNoHARMFailoverProxyProvider - Connecting to ResourceManager at /0.0.0.0:8032\n2020-11-16 11:01:00,566 [JobControl] INFO  org.apache.hadoop.conf.Configuration.deprecation - mapred.task.id is deprecated. Instead, use mapreduce.task.attempt.id\n2020-11-16 11:01:00,569 [JobControl] INFO  org.apache.hadoop.conf.Configuration.deprecation - yarn.resourcemanager.system-metrics-publisher.enabled is deprecated. Instead, use yarn.system-metrics-publisher.enabled\n2020-11-16 11:01:00,862 [JobControl] INFO  org.apache.hadoop.mapreduce.JobResourceUploader - Disabling Erasure Coding for path: /tmp/hadoop-yarn/staging/jovyan/.staging/job_1605524441629_0001\n2020-11-16 11:01:00,903 [JobControl] WARN  org.apache.hadoop.mapreduce.JobResourceUploader - No job jar file set.  User classes may not be found. See Job or Job#setJar(String).\n2020-11-16 11:01:01,001 [JobControl] INFO  org.apache.hadoop.mapreduce.lib.input.FileInputFormat - Total input files to process : 1\n2020-11-16 11:01:01,060 [JobControl] INFO  org.apache.pig.backend.hadoop.executionengine.util.MapRedUtil - Total input paths (combined) to process : 1\n2020-11-16 11:01:01,214 [JobControl] INFO  org.apache.hadoop.mapreduce.JobSubmitter - number of splits:1\n2020-11-16 11:01:01,307 [JobControl] INFO  org.apache.hadoop.conf.Configuration.deprecation - yarn.resourcemanager.system-metrics-publisher.enabled is deprecated. Instead, use yarn.system-metrics-publisher.enabled\n2020-11-16 11:01:01,658 [JobControl] INFO  org.apache.hadoop.mapreduce.JobSubmitter - Submitting tokens for job: job_1605524441629_0001\n2020-11-16 11:01:01,660 [JobControl] INFO  org.apache.hadoop.mapreduce.JobSubmitter - Executing with tokens: []\n2020-11-16 11:01:01,803 [JobControl] INFO  org.apache.hadoop.mapred.YARNRunner - Job jar is not present. Not adding any jar to the list of resources.\n2020-11-16 11:01:01,913 [JobControl] INFO  org.apache.hadoop.conf.Configuration - resource-types.xml not found\n2020-11-16 11:01:01,914 [JobControl] INFO  org.apache.hadoop.yarn.util.resource.ResourceUtils - Unable to find 'resource-types.xml'.\n2020-11-16 11:01:02,421 [JobControl] INFO  org.apache.hadoop.yarn.client.api.impl.YarnClientImpl - Submitted application application_1605524441629_0001\n2020-11-16 11:01:02,503 [JobControl] INFO  org.apache.hadoop.mapreduce.Job - The url to track the job: http://p-fb00a143-bee8-437f-b51a-dc92d20f1763:8088/proxy/application_1605524441629_0001/\n2020-11-16 11:01:02,504 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MapReduceLauncher - HadoopJobId: job_1605524441629_0001\n2020-11-16 11:01:02,504 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MapReduceLauncher - Processing aliases filtered,grouped,max_temp,records\n2020-11-16 11:01:02,504 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MapReduceLauncher - detailed locations: M: records[1,10],records[-1,-1],filtered[2,11],max_temp[4,11],grouped[3,10] C: max_temp[4,11],grouped[3,10] R: max_temp[4,11]\n2020-11-16 11:01:02,521 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MapReduceLauncher - 0% complete\n2020-11-16 11:01:02,521 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MapReduceLauncher - Running jobs are [job_1605524441629_0001]\n2020-11-16 11:01:22,807 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MapReduceLauncher - 50% complete\n2020-11-16 11:01:22,807 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MapReduceLauncher - Running jobs are [job_1605524441629_0001]\n2020-11-16 11:01:31,831 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MapReduceLauncher - Running jobs are [job_1605524441629_0001]\n2020-11-16 11:01:37,848 [main] INFO  org.apache.hadoop.yarn.client.DefaultNoHARMFailoverProxyProvider - Connecting to ResourceManager at /0.0.0.0:8032\n2020-11-16 11:01:37,867 [main] INFO  org.apache.hadoop.mapred.ClientServiceDelegate - Application state is completed. FinalApplicationStatus=SUCCEEDED. Redirecting to job history server\n2020-11-16 11:01:39,276 [main] INFO  org.apache.hadoop.yarn.client.DefaultNoHARMFailoverProxyProvider - Connecting to ResourceManager at /0.0.0.0:8032\n2020-11-16 11:01:39,294 [main] INFO  org.apache.hadoop.mapred.ClientServiceDelegate - Application state is completed. FinalApplicationStatus=SUCCEEDED. Redirecting to job history server\n2020-11-16 11:01:39,368 [main] INFO  org.apache.hadoop.yarn.client.DefaultNoHARMFailoverProxyProvider - Connecting to ResourceManager at /0.0.0.0:8032\n2020-11-16 11:01:39,377 [main] INFO  org.apache.hadoop.mapred.ClientServiceDelegate - Application state is completed. FinalApplicationStatus=SUCCEEDED. Redirecting to job history server\n2020-11-16 11:01:39,514 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MapReduceLauncher - 100% complete\n2020-11-16 11:01:39,530 [main] INFO  org.apache.pig.tools.pigstats.mapreduce.SimplePigStats - Script Statistics: \n\nHadoopVersion\tPigVersion\tUserId\tStartedAt\tFinishedAt\tFeatures\n3.3.0\t0.17.0\tjovyan\t2020-11-16 11:00:58\t2020-11-16 11:01:39\tGROUP_BY,FILTER\n\nSuccess!\n\nJob Stats (time in seconds):\nJobId\tMaps\tReduces\tMaxMapTime\tMinMapTime\tAvgMapTime\tMedianMapTime\tMaxReduceTime\tMinReduceTime\tAvgReduceTime\tMedianReducetime\tAlias\tFeature\tOutputs\njob_1605524441629_0001\t1\t1\t5\t5\t5\t5\t5\t5\t5\t5\tfiltered,grouped,max_temp,records\tGROUP_BY,COMBINER\thdfs://localhost:9000/user/jovyan/output,\n\nInput(s):\nSuccessfully read 5 records (906 bytes) from: \"hdfs://localhost:9000/user/jovyan/sample_orig.txt\"\n\nOutput(s):\nSuccessfully stored 2 records (17 bytes) in: \"hdfs://localhost:9000/user/jovyan/output\"\n\nCounters:\nTotal records written : 2\nTotal bytes written : 17\nSpillable Memory Manager spill count : 0\nTotal bags proactively spilled: 0\nTotal records proactively spilled: 0\n\nJob DAG:\njob_1605524441629_0001\n\n\n2020-11-16 11:01:39,535 [main] INFO  org.apache.hadoop.yarn.client.DefaultNoHARMFailoverProxyProvider - Connecting to ResourceManager at /0.0.0.0:8032\n2020-11-16 11:01:39,563 [main] INFO  org.apache.hadoop.mapred.ClientServiceDelegate - Application state is completed. FinalApplicationStatus=SUCCEEDED. Redirecting to job history server\n2020-11-16 11:01:39,635 [main] INFO  org.apache.hadoop.yarn.client.DefaultNoHARMFailoverProxyProvider - Connecting to ResourceManager at /0.0.0.0:8032\n2020-11-16 11:01:39,646 [main] INFO  org.apache.hadoop.mapred.ClientServiceDelegate - Application state is completed. FinalApplicationStatus=SUCCEEDED. Redirecting to job history server\n2020-11-16 11:01:39,765 [main] INFO  org.apache.hadoop.yarn.client.DefaultNoHARMFailoverProxyProvider - Connecting to ResourceManager at /0.0.0.0:8032\n2020-11-16 11:01:39,775 [main] INFO  org.apache.hadoop.mapred.ClientServiceDelegate - Application state is completed. FinalApplicationStatus=SUCCEEDED. Redirecting to job history server\n2020-11-16 11:01:39,851 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MapReduceLauncher - Success!\n2020-11-16 11:01:39,902 [main] INFO  org.apache.pig.Main - Pig script completed in 44 seconds and 888 milliseconds (44888 ms)\n","output_type":"stream"}],"execution_count":null},{"cell_type":"code","metadata":{"tags":[],"cell_id":"00004-e3a57f18-2ed0-4de6-a232-778d00f1814a","output_cleared":false,"source_hash":"7f00156a","execution_millis":4188,"execution_start":1605524570015},"source":"! $HADOOP_HOME/bin/hdfs dfs -get output .","outputs":[{"name":"stdout","text":"get: Call From p-fb00a143-bee8-437f-b51a-dc92d20f1763/172.2.135.35 to localhost:9000 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused\r\n","output_type":"stream"}],"execution_count":null},{"cell_type":"code","metadata":{"tags":[],"cell_id":"00003-cee65112-8e33-4198-a18b-c2d6a16af25d","output_cleared":false,"source_hash":"54925d8","execution_millis":22369,"execution_start":1605524540780},"source":"%%bash\n$HADOOP_HOME/bin/mapred --daemon stop historyserver\n$HADOOP_HOME/sbin/stop-yarn.sh\n$HADOOP_HOME/sbin/stop-dfs.sh\n","outputs":[{"name":"stdout","text":"Stopping nodemanagers\nlocalhost: WARNING: nodemanager did not stop gracefully after 5 seconds: Trying to kill with kill -9\nStopping resourcemanager\nStopping namenodes on [localhost]\nStopping datanodes\nStopping secondary namenodes [p-fb00a143-bee8-437f-b51a-dc92d20f1763]\n","output_type":"stream"}],"execution_count":null},{"cell_type":"code","metadata":{"tags":[],"cell_id":"00008-bf492ce6-8344-4108-9db2-07e2cf00ec5d","output_cleared":false,"source_hash":"b623e53d","execution_millis":2,"execution_start":1605524385890},"source":"","outputs":[],"execution_count":null}],"nbformat":4,"nbformat_minor":2,"metadata":{"orig_nbformat":2,"deepnote_notebook_id":"6acb2c26-ddc8-48ad-85cb-e025e400398c","deepnote_execution_queue":[]}}