{"cells":[{"cell_type":"code","metadata":{"tags":[],"cell_id":"00000-9d2fa461-2df2-4234-9d31-a2b301cc1857","output_cleared":false,"source_hash":"b3ad563b","execution_millis":7,"execution_start":1603709994317},"source":"%%file number_of_words_map.py\n#!/usr/bin/env python\n\nimport re\nimport sys\n\ni = 0\nfor line in sys.stdin:\n  # read year\n  words = line.split()\n  # if temp. is valid and of correct quality, write year & temp\n  print(\"%s\\t%s\" % (\"s\", len(words)))\n","outputs":[{"name":"stdout","text":"Overwriting number_of_words_map.py\n","output_type":"stream"}],"execution_count":null},{"cell_type":"code","metadata":{"tags":[],"cell_id":"00001-146d247c-05a0-4bd5-a1f4-6be7d0b66df2","output_cleared":false,"source_hash":"ab37c204","execution_millis":3,"execution_start":1603709994327},"source":"%%file number_of_words_reduce.py\n#!/usr/bin/env python\nimport sys\n\nlast_key = None\nmax_val = -sys.maxsize-1\n\nfor line in sys.stdin:\n  # get key and value pair\n  key, val = line.split(\"\\t\")\n  val = int(val) \n\n  if last_key == key:  # we continue reading same key\n    max_val = max(max_val, val) # update maximum\n\n  else:  # we move to a new key (or it is the first read)\n\n    if last_key: # if it is not the first read, print key\n       print(\"%s\\t%s\" % (last_key, max_val))\n    # set new key and initialize maximum \n    last_key = key\n    max_val = val\n\n# handling last key (if we ever had one)\nif last_key:\n  print(\"%s\\t%s\" % (last_key, max_val))","outputs":[{"name":"stdout","text":"Overwriting number_of_words_reduce.py\n","output_type":"stream"}],"execution_count":null},{"cell_type":"code","metadata":{"tags":[],"cell_id":"00002-3f7fdd2c-76c6-4d36-8f1c-8ab00a136c0a","output_cleared":false,"source_hash":"f4af9590","execution_millis":1557,"execution_start":1603709994332},"source":"! chmod +x number_of_words_map.py\n! chmod +x number_of_words_reduce.py","outputs":[],"execution_count":null},{"cell_type":"code","metadata":{"tags":[],"cell_id":"00003-9b0f0366-7022-4de7-b66a-8c2ee65fcbcc","output_cleared":false,"source_hash":"6bead57f","execution_millis":4838,"execution_start":1603709995898},"source":"! $HADOOP_HOME/bin/hadoop jar $HADOOP_HOME/share/hadoop/tools/lib/hadoop-streaming-*.jar -input input/sample.txt -output output2 -mapper number_of_words_map.py -reducer number_of_words_reduce.py","outputs":[{"name":"stdout","text":"2020-10-26 10:59:58,626 INFO impl.MetricsConfig: Loaded properties from hadoop-metrics2.properties\n2020-10-26 10:59:58,818 INFO impl.MetricsSystemImpl: Scheduled Metric snapshot period at 10 second(s).\n2020-10-26 10:59:58,818 INFO impl.MetricsSystemImpl: JobTracker metrics system started\n2020-10-26 10:59:58,839 WARN impl.MetricsSystemImpl: JobTracker metrics system already initialized!\n2020-10-26 10:59:58,991 INFO mapred.FileInputFormat: Total input files to process : 1\n2020-10-26 10:59:59,011 INFO mapreduce.JobSubmitter: number of splits:1\n2020-10-26 10:59:59,257 INFO mapreduce.JobSubmitter: Submitting tokens for job: job_local1280749681_0001\n2020-10-26 10:59:59,262 INFO mapreduce.JobSubmitter: Executing with tokens: []\n2020-10-26 10:59:59,490 INFO mapreduce.Job: The url to track the job: http://localhost:8080/\n2020-10-26 10:59:59,492 INFO mapreduce.Job: Running job: job_local1280749681_0001\n2020-10-26 10:59:59,502 INFO mapred.LocalJobRunner: OutputCommitter set in config null\n2020-10-26 10:59:59,506 INFO mapred.LocalJobRunner: OutputCommitter is org.apache.hadoop.mapred.FileOutputCommitter\n2020-10-26 10:59:59,518 INFO output.FileOutputCommitter: File Output Committer Algorithm version is 2\n2020-10-26 10:59:59,518 INFO output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n2020-10-26 10:59:59,589 INFO mapred.LocalJobRunner: Waiting for map tasks\n2020-10-26 10:59:59,596 INFO mapred.LocalJobRunner: Starting task: attempt_local1280749681_0001_m_000000_0\n2020-10-26 10:59:59,636 INFO output.FileOutputCommitter: File Output Committer Algorithm version is 2\n2020-10-26 10:59:59,636 INFO output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n2020-10-26 10:59:59,665 INFO mapred.Task:  Using ResourceCalculatorProcessTree : [ ]\n2020-10-26 10:59:59,681 INFO mapred.MapTask: Processing split: file:/home/jovyan/work/input/sample.txt:0+76\n2020-10-26 10:59:59,691 INFO mapred.MapTask: numReduceTasks: 1\n2020-10-26 10:59:59,802 INFO mapred.MapTask: (EQUATOR) 0 kvi 26214396(104857584)\n2020-10-26 10:59:59,803 INFO mapred.MapTask: mapreduce.task.io.sort.mb: 100\n2020-10-26 10:59:59,803 INFO mapred.MapTask: soft limit at 83886080\n2020-10-26 10:59:59,803 INFO mapred.MapTask: bufstart = 0; bufvoid = 104857600\n2020-10-26 10:59:59,803 INFO mapred.MapTask: kvstart = 26214396; length = 6553600\n2020-10-26 10:59:59,807 INFO mapred.MapTask: Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer\n2020-10-26 10:59:59,834 INFO streaming.PipeMapRed: PipeMapRed exec [/home/jovyan/work/./number_of_words_map.py]\n2020-10-26 10:59:59,844 INFO Configuration.deprecation: mapred.work.output.dir is deprecated. Instead, use mapreduce.task.output.dir\n2020-10-26 10:59:59,845 INFO Configuration.deprecation: map.input.start is deprecated. Instead, use mapreduce.map.input.start\n2020-10-26 10:59:59,851 INFO Configuration.deprecation: mapred.task.is.map is deprecated. Instead, use mapreduce.task.ismap\n2020-10-26 10:59:59,851 INFO Configuration.deprecation: mapred.task.id is deprecated. Instead, use mapreduce.task.attempt.id\n2020-10-26 10:59:59,852 INFO Configuration.deprecation: mapred.tip.id is deprecated. Instead, use mapreduce.task.id\n2020-10-26 10:59:59,852 INFO Configuration.deprecation: mapred.local.dir is deprecated. Instead, use mapreduce.cluster.local.dir\n2020-10-26 10:59:59,852 INFO Configuration.deprecation: map.input.file is deprecated. Instead, use mapreduce.map.input.file\n2020-10-26 10:59:59,852 INFO Configuration.deprecation: mapred.skip.on is deprecated. Instead, use mapreduce.job.skiprecords\n2020-10-26 10:59:59,853 INFO Configuration.deprecation: map.input.length is deprecated. Instead, use mapreduce.map.input.length\n2020-10-26 10:59:59,853 INFO Configuration.deprecation: mapred.job.id is deprecated. Instead, use mapreduce.job.id\n2020-10-26 10:59:59,853 INFO Configuration.deprecation: user.name is deprecated. Instead, use mapreduce.job.user.name\n2020-10-26 10:59:59,854 INFO Configuration.deprecation: mapred.task.partition is deprecated. Instead, use mapreduce.task.partition\n2020-10-26 10:59:59,897 INFO streaming.PipeMapRed: R/W/S=1/0/0 in:NA [rec/s] out:NA [rec/s]\n  File \"/home/jovyan/work/./number_of_words_map.py\", line 13\n    i++\n      ^\nSyntaxError: invalid syntax\n2020-10-26 10:59:59,927 INFO streaming.PipeMapRed: PipeMapRed failed!\njava.lang.RuntimeException: PipeMapRed.waitOutputThreads(): subprocess failed with code 1\n\tat org.apache.hadoop.streaming.PipeMapRed.waitOutputThreads(PipeMapRed.java:326)\n\tat org.apache.hadoop.streaming.PipeMapRed.mapRedFinished(PipeMapRed.java:539)\n\tat org.apache.hadoop.streaming.PipeMapper.close(PipeMapper.java:130)\n\tat org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:61)\n\tat org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)\n\tat org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:465)\n\tat org.apache.hadoop.mapred.MapTask.run(MapTask.java:349)\n\tat org.apache.hadoop.mapred.LocalJobRunner$Job$MapTaskRunnable.run(LocalJobRunner.java:271)\n\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)\n\tat java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)\n\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n\tat java.base/java.lang.Thread.run(Thread.java:834)\n2020-10-26 10:59:59,927 INFO streaming.PipeMapRed: MRErrorThread done\n2020-10-26 10:59:59,936 INFO mapred.LocalJobRunner: map task executor complete.\n2020-10-26 10:59:59,938 WARN mapred.LocalJobRunner: job_local1280749681_0001\njava.lang.Exception: java.lang.RuntimeException: PipeMapRed.waitOutputThreads(): subprocess failed with code 1\n\tat org.apache.hadoop.mapred.LocalJobRunner$Job.runTasks(LocalJobRunner.java:492)\n\tat org.apache.hadoop.mapred.LocalJobRunner$Job.run(LocalJobRunner.java:552)\nCaused by: java.lang.RuntimeException: PipeMapRed.waitOutputThreads(): subprocess failed with code 1\n\tat org.apache.hadoop.streaming.PipeMapRed.waitOutputThreads(PipeMapRed.java:326)\n\tat org.apache.hadoop.streaming.PipeMapRed.mapRedFinished(PipeMapRed.java:539)\n\tat org.apache.hadoop.streaming.PipeMapper.close(PipeMapper.java:130)\n\tat org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:61)\n\tat org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)\n\tat org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:465)\n\tat org.apache.hadoop.mapred.MapTask.run(MapTask.java:349)\n\tat org.apache.hadoop.mapred.LocalJobRunner$Job$MapTaskRunnable.run(LocalJobRunner.java:271)\n\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)\n\tat java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)\n\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n\tat java.base/java.lang.Thread.run(Thread.java:834)\n2020-10-26 11:00:00,497 INFO mapreduce.Job: Job job_local1280749681_0001 running in uber mode : false\n2020-10-26 11:00:00,499 INFO mapreduce.Job:  map 0% reduce 0%\n2020-10-26 11:00:00,511 INFO mapreduce.Job: Job job_local1280749681_0001 failed with state FAILED due to: NA\n2020-10-26 11:00:00,521 INFO mapreduce.Job: Counters: 0\n2020-10-26 11:00:00,522 ERROR streaming.StreamJob: Job not successful!\nStreaming Command Failed!\n","output_type":"stream"}],"execution_count":null},{"cell_type":"code","metadata":{"tags":[],"cell_id":"00004-e0c8fa6b-3970-4c6a-8c16-ff40c1c4c249","output_cleared":false,"source_hash":"2bd67b20","execution_millis":840,"execution_start":1603710000745},"source":"!cat output2/part-00000","outputs":[{"name":"stdout","text":"cat: output2/part-00000: No such file or directory\r\n","output_type":"stream"}],"execution_count":null}],"nbformat":4,"nbformat_minor":2,"metadata":{"orig_nbformat":2,"deepnote_notebook_id":"4512a7d8-5d02-4334-a502-81c982c2c6ae","deepnote_execution_queue":[]}}