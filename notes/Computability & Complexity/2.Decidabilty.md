---
attachments: [COL_relationship.png]
tags: [CC]
title: 2.Decidabilty
created: '2020-05-23T09:41:56.041Z'
modified: '2020-05-24T17:53:39.822Z'
---

# 2.Decidabilty

<h2 style="color:#BB86FC">Pre-requisits</h2>

[//]: # (Primary = #BB86FC)
[//]: # (Secondary = #03DAC5)
[//]: # (Secondary = #FF0266)


Important stuff to know beforehand: 

Decidable: A decision problem that can be solved by an algorithm that halts on all inputs in a finite number of steps. The associated language is called a decidable language.


Turing Recognizable: A language is Recognizable iff there is a Turing Machine which will halt and accept only the strings in that language and for strings not in the language, the TM either rejects, or does not halt at all.

Context-Free: Context-free grammars (CFGs) are used to describe context-free languages. A context-free grammar is a set of recursive rules used to generate patterns of strings. A context-free grammar can describe all regular languages and more, but they cannot describe all possible languages.

Regular: A regular language is a language that can be expressed with a regular expression or a deterministic or non-deterministic finite automata or state machine. A language is a set of strings which are made up of characters from a specified alphabet, or set of symbols. Regular languages are a subset of the set of all strings.

Decidable vs. Recognizable: A turing machine is turing recognizable iff a a turing machine accepts all its valid input strings and either rejects or never halts on invalid one. A turing machine is decidable if the turing machine accepts all of its valid inputs and rejects all of its invalid inputs.

<h2 style="color:#BB86FC">Deciable Languages :</h2>

* We represent the various computational problems by languages.

<h3 style="color:#03DAC5">Theorem 1 :</h3>
Let  $A_{DFA} = \{\langle B, w \rangle\ | \text{ B is DFA that accepts input string }w\}$ <br>
$A_{DFA}$ is a decidable language.


<h4 style="color:#FF0266">Proof Idea :</h4>

We simply need to present a $TM$ $M$ that decides $A_{DFA}$. 

M = "On input $\langle B, w \rangle$, where B is a DFA and $w$ is a string:
  1. Simulate B on input w
  2. If the simulation ends in an accept state, $accept$. If it ends in a nonacception state, $reject$.


<h4 style="color:#FF0266">Explaining the input style:</h4>
$\langle B, w\rangle$ uss a representation of a DFA B together with a string w. One reasonable representation of B is simply a list of its five componenets: $Q$, $\Sigma$, $\delta$, $q_0$ and $F$. So when a turing machine M receives its input, LM first determines whether it properly represents a DFA B and a string w. If not, M rejects. <br>
The turing machine M then carries out the simulation directly. It keeps track of B's current state and B's current position in the input string w by writing all this information down on its tape. Initially, B's current is $q_0$ and B's current input position is the leftmost symbol of $w$. The states and position are updated according to the specified transition function $\delta$. When M finishes processing the last symbol of $w$, $M$ accepts the input if B is in an accepting state; $M$ rejects the input if B is in a nonaccepting state.


<h3 style="color:#03DAC5">Theorem 2</h3>
Let $A_{NFA} = \{\langle B, w \rangle | \text{B is an NFA that accepts input string} w\}$ <br>
$A_{NFA}$ is a decidable language.

<h4 style="color:#FF0266">Proof Idea :</h4>

Lets present the turing machine N that decides $A_{NFA}$. There are two ways we can go about this proof.
We could simply reuse the first proof we used but instead of simulating a DFA we simulate an NFA. Instead, we'll illustrate a new idea. Let N be use M as a subroutine. Becuase M is designed to only work with DFA's then we would want to convert our NFA to a DFA before feeding it as an input to M. 

N = "On input $\langle B, w \rangle$, where B is an NFA a $w$ is a string:
  1. Convert NFA B to a DFA C using the procedure for this conversion seen in the previous course Formal Languages and Logic.
  2. Run TM M from Theorem 1 on input $\langle C, w \rangle$
  3. If M accepts $w$ then $accept$; otherwise, $reject$.


<h3 style="color:#03DAC5">Theorem 3</h3>
Let $A_{REX} = \{\langle R, w \rangle | \text{R is a regular expression that generates input string } w\}$ <br>
$A_{REX}$ is a decidable language.

<h4 style="color:#FF0266">Proof Idea :</h4>

Let TM P be the turing machine which decides $A_{REX}$. We could follow any of the two ideas introduct in the 2 previous proof. We can assume that P simulates the regular expression or that our turing machine converts the regular expression to a DFA or NFA and either use M or N respecitvely to check if the input string is valid.

P = "On input $\langle R, w\rangle$, where R is a regular expression that generates the input string $w$:
  1. Convert regular expression R to an NFA using the algorithms and theorems introduct in Formal Languages and Logic.
  2. Run TM N on input $\langle R, w \rangle$
  3. If N accepts $w$ then $accept$; otherwise, $reject$.


<h3 style="color:#03DAC5">Re-Cap</h3>

Theorems 1, 2 and 3 illustrate that for decidability purposes, it is equivalent to present the Turing machine with a DFA, an NFA, or a regular expression because the machine can convert one form of encoding to another. <br>

Now, we turn to $emptiness$ testing for the language of a finite automaton. In the next proof, we determine whether or not a dinite automaton accepts any strings at all.

<h3 style="color:#03DAC5">Theorem 4</h3>

Let $E_{DFA} = \{ \langle A \rangle | \text{A is a DFA and } L(A) = \empty \}$
$E_{DFA}$ is a decidable language.

<h4 style="color:#FF0266"> Proof Idea :</h4>
In order to check that a language is empty we need to make sure that no accept state is reachable, meaning that it does not contain valid input.
A DFA accepts some string iff reaching an accept state from the start state by traveling along the arrows of the DFA is possible. To test this condition, we can design a TM T that uses a marking algorithm. <br><br>

T = "On input $\langle A, w \rangle$, where A is a DFA:
  1. Mark start state of A.
  2. Repeat until there are no states left to be marked:
    3. Mark any state that has a transition coming into it from any state that is already marked.
  4. If no accept state is marked, $accept$; otherwise, reject.

<h4 style="color:#FF0266">Important</h4>

Since we have already proved that we can prove this for any other machine (NFA, Regular Expression) using the ideas we got from the previous proofs. 


<h3 style="color:#03DAC5">Theorem 5</h3>

Let $EQ_{DFA} = \{\langle A, B\rangle | \text{A and B are DFAs and} L(A) = L(B) \}$
$EQ_{DFA}$ is a decidable language.

<h4 style="color:#FF0266"> Proof Idea :</h4>

Let's construct a new DFA c from A and b, where C accepts only those strings that are accepted by either A or B but not by both. Thus, if A and B recognize the same language, C will accept nothing. The language of C is now:
<div style="text-align: center">
$L(C) = \left( L(A) \cap L(B) \right) \cup \left( \overline{L(A)} \cap L(B) \right)$
</div>
<br>
The symmetric difference is important here because $L(C) = \empty$ iff $L(A) = L(B)$.  We can now construct C from A and B with the constructions for proving the class of regular languages closed uner complementation, union, and intersection. These constructions are algorithms that can be carried out by Turing Machines. Once we have constructed C, we can use the previous theorem to test whether $L(C)$ are empty. If it's empty then $L(A) = L(B)$.
<br><br>

F = "On input $\langle A, B\rangle$, where A and B are DFAs:
  1. Construct DFA C as described.
  2. Run TM T from the previous theorem on $\langle C \rangle$
  3. If T accepts, $accept$; otherwise, $reject$.

<h3 style="color:#03DAC5">Conclusion</h3>

We can now establish the relationshipn among the four main classes of languages that we have described so far: regular, context-free, decidable, and Turing-recognizable.

![Icon](@attachment/COL_relationship.png)

<h2 style="color:#BB86FC">Undecidability</h2>

There is a specific problem that is algorithmically unsolvable. Computers appear to be so powerful that you may believe that all problems will eventually yield to them. The theorem presented here demonstrates that computers are limited in a fundamental way.

<h3 style="color:#03DAC5">Theorem 6</h3>
 
 Let $A_{TM}$ be a turing machine which accepts a given string but that is not decidable.
$A_{TM} = \{\langle M, w \rangle | \text{M is a TM and M accepts }w\}$.
$A_{TM}$ is undecidable.

<h4 style="color:#FF0266">Proof Idea :</h4>
Before we get to the proof, let's first observe that $A_{TM}$ is Turing-recognizable. Thus, this theorem shows that recognizers are more powerful than deciders. Requiring a TM to halt on lal inputs restricts the languages it recognizes. The following TM U recognizes $A_{TM}$

U = "On input $\langle M, w \rangle$, where M is a TM and w is a string:
  1. Simulate M on input $w$.
  2. If M ever enters the accept state, $accept$; if M ever enters the reject state, $reject$.

Note that this machine loops on input $\langle M, w \rangle$ if M loops on $w$, which is why this machine does not decide $A_{TM}$. If the algorithm had some way of recognizing that  M was not halting on $w$, it could reject it in this case. However, an algorithm has no way to make this determination as we shall see. 

<h4 style="color:#FF0266">Diagonalization Method:</h4>

The diagonalization method was a method introduced by mathematecian Georg Cantor in 1873. The diagonalization method solves the problem of determining whether two infinite sets are larger than the other or whether they are of the same size. We can easily determine this for finite sets since we can simply count but how to we do so for infinite sets since we'll never stop counting? Let us formally define diagonalization:

<br>

Assume that we have sets A and B and a function $f$ from A to B. Say that $f$ is <b>one-to-one</b> if it never maps two different elements to the same place-that is, if $f(a) \ne f(b)$. Say that $f$ is <b>onto</b> if it hits every element of B-that is, if for every $b \in B$ there is an $a \in A$ such that $f(a)=b$. Say that A and B are the <b>same size</b> if there is a one-to-one, onto function $f : A \rightarrow B$. A function that is both one-to-one and onto is called a <b>correspondence</b>. In a correspondence, every element of A maps to a unique element of B and each element of B has a unique element of A mapping to it. A correspondence is simply a way of pairing the elements of A with elements of B.


* Example:

Let $N$ be the set of natural numbers {1, 2, 3, ...} and let $\varepsilon$ be the set of even real number {2, 4, 6, ...}. Using Cantor's definition of size, we can see that $N$ and $\varepsilon$  have the same size. The correspondance $f$ mapping $\N$ to $\varepsilon$ is simply $f(n) = 2n$. We can visualize $f$ more easily with the help of a table.

<table style="text-align: center">
<tr>
  <th>n</th>
  <th>f(n)</th>
</tr>
<tr>
  <td>1</td>
  <td>2</td>
</tr>
<tr>
  <td>2</td>
  <td>4</td>
</tr>
<tr>
  <td>3</td>
  <td>6</td>
</tr>
<tr>
  <td>.</td>
  <td>.</td>
</tr>
</table>

Intuitively, $\varepsilon$ seems smaller than $N$ because $\varepsilon$ is a proper subset of $N$. But pairing each member of $N$ with its own member of $\varepsilon$ is possible, so we declare these sets to be the same size. A good definition we can keep in mind is :
<br>
A set A is <b>countable</b> if either it is finite or it has the same size as $\N$.

The preceding theorem has an important application to the theory of computation :
<font color="yellow"><b>Some languages are not Turing-recognizable.</b></font>

<h4 style="color:#FF0266">Proof (contd.)</h4>

We're now ready to prove our initial theorem :
$A_{TM} = \{\langle M, w \rangle | \text{M is a TM and M accepts }w\}$.
$A_{TM}$ is undecidable.


We assume that $A_{TM}$ is decidable and obtain a contradiction. Suppose that H is a decider for $A_{TM}$. On input $\langle M, w \rangle$, where $M$ is a $TM$ and $w$ is a string, $H$ halts and accepts if $M$ accepts $w$. Furthermore, $H$ halts and rejects if $M$ fails to accept $w$. In other words, we assume that $H$ is a TM, where:
```katex

    H \left( \langle M, w \rangle \right)= 
\begin{cases}
    accept,& \text{if M accepts }w.\\
    reject,& \text{if M does not accept }w.
\end{cases}

```

Now we construct a new Turing machine $D$ with $H$ as a subroutine. This new TM calls $H$ to determine $M$ does when the input to $M$ is its own description $\langle M \rangle$. Once $D$ has determined his information, it does the opposite. That is, it rejects if $M$ accepts and accepts if $M$ does not accept. The following is a description of D.

D = "On input $\langle M \rangle$, where $M$ is a TM:
  1. Run H on input $\langle M, \langle M \rangle \rangle$
  2. Output the opposite of what $H$ outputs. That is, if $H$ accepts, $reject$; and if $H$ rejects, $accept$."

In summary,
```katex

    D \left( \langle M, w \rangle \right)= 
\begin{cases}
    accept,& \text{if M  does not accept} \langle M \rangle.\\
    reject,& \text{if M accepts} \langle M \rangle.
\end{cases}

```

What happens when we run $D$ with its own description $\langle D \rangle$ as input? In that case we get

```katex

    D \left( \langle D, w \rangle \right)= 
\begin{cases}
    accept,& \text{if D  does not accept} \langle D \rangle.\\
    reject,& \text{if D accepts} \langle D \rangle.
\end{cases}

```

No matter what $D$ does, it is forced to do the opposite, which is obviously a contradiction. Thus, neither TM $D$ nor TM $H$ can exist.

<h3 style="color:#03DAC5">Theorem 7</h3>

A language is decidable iff it is Turing-recognizable and co-Turing-recognizable. In other words, a language is decidable exactly when both it and its complement are Turing-recognizable.

<h4 style="color:#FF0266">Proof:</h4>
We have two directions to prove. First, if A is decidable we can easily see that both $A$ and its complement $\bar{A}$ are Turing-recognizable. Any decidable language is Turing-recognizable, and the complement of a decidable also is decidable.

For the other direction, if both $A$ and $\bar{A}$ are Turing recognizable, we let $M_1$ be the recognizer for $A$ and $M_2$ be the recognizer for $\bar{A}$. The following Turing machine $M$ is a decider for $A$.

M = "On input w:
  1. Run both $M_1$ and $M_2$ on input w in parallel.
  2. If $M_1$ accepts, $accepts$; if $M_2$ accepts, $reject$.

Now we show that $M$ decides $A$. Every string $w$ is either in $A$ or $\bar{A}$. Therefore, either $M_1$ or $M_2$ must accept $w$. Because $M$ halts whenever $M_1$ or $M_2$ accepts, $M$ always halts and so it is a decider. Furthermore, it accepts all strings in $A$ and rejects all strings not in $A$. So $M$ is a decider for $A$, and thus $A$ is decidable.

<h3 style="color:#03DAC5">Corollary </h3>

$\overline{A_{TM}}$ is not Turing-recognizable.

<h4 style="color:#FF0266">Proof:</h4>

We know that $A_{TM}$ is Turing-recognizable. If $\overline{A_{TM}}$ also were Turing-recognizable, $A_{TM}$ would be decidable. Theorem 7 tells us that $A_{TM}$ is not decidable, so $A_{TM}$ must not be Turing-recognizable.


