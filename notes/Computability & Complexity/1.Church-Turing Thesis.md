---
tags: [CC]
title: 1.Church-Turing Thesis
created: '2020-05-24T07:46:00.109Z'
modified: '2020-05-24T17:40:52.771Z'
---

# 1.Church-Turing Thesis

[//]: # (Primary = #BB86FC)
[//]: # (Secondary = #03DAC5)
[//]: # (Secondary = #FF0266)

<h2 style="color:#BB86FC">Turing Machines</h2>

<h3 style="color:#03DAC5">Definitions and Intro</h3>

The turing machine model uses an infinite tape as its unlimited memory. It has a tape head that can read and write symbols and move around on the tape. Initially the tape contains only the input string and is blank everywhere else. If the machine needs to store information, it may write this information on the tape. To read the information that it has written, the machine can move its head back over it. The machine continues computing until it decides to produce an output. The outputs $accept$ and $reject$ are obtaibed by entering designated accepting and rejecting states. If it doesn't enter an accepting or rejecting state, it will go on forever, never halting.

<h4 style="color:#FF0266">Definition 1</h4>

A __turing machine__ is a 7-Tuple $(Q,\Sigma, \Gamma, \delta, q_0, q_{accept}, q_{reject})$, where $Q, \Sigma, \Gamma$
are all finite sets and :
1. $Q$ is a set of states
2. $\Sigma$ is the input alphabet not containing the __blank symbol__ $\sqcup$
3. $\Gamma$ is the tape alphabet, where $\sqcup \in \Gamma$ and $\Sigma \subseteq \Gamma$
4. $\delta : Q \times \Sigma \rightarrow Q \times \Sigma \times \{L, R\}$ is the transition function,
5. $q_0 \in Q$ is the start state
6. $q_{accept}$ is the accepte state and,
7. $q_{reject}$ is the accepte state, where $q_{accept} \neq q_{reject}$

---

As a Turing machine computes, changes occur in the current state, the current tape contents, and the current head location. A setting of these three items is called a <b>configuration</b> of the Turing machine. Configurations often are represented in a special way. For a state $q$ and two strings $u$ and $v$ over the tape alphabet $\Gamma$, we write $uqv$ for the configuration where the current state is $q$, the current tape contents is $uv$, and the current head location is the first symbol of $v$. The tape contains only blanks following the last symbol of $v$.  

The <b>start configuration</b> of M on input $w$ is the configuration $q_0w$, which indicates that the machine is in the start state $q_0$ with its head at the leftmost position on the tape. In an <b>accepting configuration</b>, the state of the configuration is $q_{accept}$. In a <b>rejecting configuration</b>, the state of the configuration is $q_{reject}$. Accepting and rejecting configurations are <b>halting configurations</b> and do not yield further configurations. Because the machine is defined to halt when in the states $q_{accept}$ and $q_{reject}$, we equivalently could have defined the transition function to have the more complicated form $\delta : Q^` \times \Gamma \rightarrow Q \times \Gamma \times \{L, r\}$

<h4 style="color:#FF0266">Definition 2</h4>

A Turing machine M accepts input $w$ if a sequence of configurations $C_1$, $C_2$, . . . , $C_k$ exists, where

1. $C_1$ is the start configuration of M on input w.
2. each $C_i$ yields $C_{i + 1}$.
3. $C_k$ is an accepting configuration.

<h4 style="color:#FF0266">Note</h4>

The collection of strings that $M$ accepts is <b>the language of M,</b> or <b>the language recognized by M</b>, denoted $L(M)$.

<h4 style="color:#FF0266">Definition 3</h4>
We call a language <b>turing recognizable</b> if some Turing machine recognizes it.

<h4 style="color:#FF0266">Definition 4</h4>
Call a language Turing-decidable or simply decidable if some Turing machine decides it. In other words, turing machines that halt on all inputs and never loop.

every decidable language is turing recogizable.

<h3 style="color:#03DAC5">Examples of Turing Machines</h3>

<h4 style="color:#FF0266">Example 1</h4>

Here we describe a Turing machine (TM) $M_2$ that decides $A = \{0^{2^n} | n \geq 0\}$, the language consisting of all strings of $0$s whose length is a power of 2.

$M_2$ = "On input string $w$:
  1. Sweep left to right to write across the tape, crossing off every other $O$.
  2. If in stage 1 the tape contained a single $0$, $accept$.
  3. If in stage 1 the tape contained more than a single $0$ and the number of $0$s was odd, $reject$.
  4. Return the head to the left-hand end of the tape.
  5. Go to stage $1$."

Each iteration of stage 1 cuts the number of $0$s in half. As the machine sweeps across the tape in stage $1$, it keeps track of whether the number fo $0$s seen is even or odd. If that number is odd and greater than $1$, the original number of $0$s in the input could not have been a power of $2$. Therefore, the machine rejects this instance.  However, if the number of $0$s seen is $1$, the original number must have been a power of $2$. So in this case, the machine accpets. Now we give the formal description of the turing machine. 

$M_2 = (Q, \Sigma, \Gamma, \delta, q_1, q_{accept}, q_{reject})$:

* $Q = \{q_1, q_2, q_3, q_4, q_5, q_{accept}, q_{reject}\}$,
* $\Sigma = \{0\}$, and
* $\Gamma = \{0, x, \sqcup\}$
* We describe $\delta$ with a state diagram (See Page 172, Figure 3.8).
* The start, accept and reject states are $q_1$, $q_accept$, and $q_reject$, respecitvely.


<h4 style="color:#FF0266">Example 2</h4>

Let's now introduce a turing machine for testing membership in the language $B = \{ w\#w | w \in \{0,1\}^*\}$. We want the TM to accept if its input is a member of $B$ and to reject otherwise. In summary, $M_1$'s algorithm is as follows:

$M_1$ = "On input string $w$:
1. Zig-zag across the tape to corresponding positions on either side of the $\#$ symbol to check whether these positions contain the same symbol. If they do not, or if no $\#$ is found, $reject$. Cross off symbols as they are checked to keep track of which symbols correspond.
2. When all symbols to the left of the $\#$ have been crossed off, check for any remaining symbols to the right of the $\#$? If any symbols remain, $reject$; otherwise, $accept$."

The following is a formal description of $M_1 = (Q, \Sigma, \Gamma, \delta, q_1, q_{accept}, q_{reject})$.

* $Q = \{q_1, ..., q_8, q_{accept}, q_{reject}\}$,
* $\Sigma = \{0, 1, \#\}$, and $\Gamma = \{0, 1, \#, x, \sqcup\}$.
* We describe $\delta$ with a state diagram. (See Figure in page 173)
* The start, accept and reject states are $q_1$, $q_{accept}$, and $q_{reject}$, respectively.

In 

<h2 style="color:#BB86FC">Variants of Turing Machines</h2>

Alternative definitions of Turing machines exist in large amounts, including versions with multiple tapes or with nondeterminism. They are called <b>variants</b> of the Turing machine model. The original model and its reasonable variants all have the same power-they recognize the same class of languages. In this section, we describe some of these variants and the proofs of equivalence in power. We call this invariance to certain changes in the definition $robustness$

<h3 style="color:#03DAC5">Multitape Turing Machines</h3>

A multitape Turing machine is like an ordinary Turing machine with several tapes. Each tape has its own head for reading and writing. Initially the input appears on the tape 1, and other start out blank. The transition function is changed to allow for reaching, writing and moving the heads on same or all the tapes simultaneously. Formally, it is

$\delta : Q \times \Gamma^k \rightarrow Q \times \Gamma^k \times \{ L, R, S\}^k$,

where $k$ is the number of tapes. The expression

$\delta(q_i, a_1, ..., a_k) = (q_j, b_1, ..., b_k, L, R, ..., L)$

means that if the machine is in state $q_i$ and heads 1 through $k$ are reading symbols $a_1$ through $a_k$, the machine goes to state $q_j$, writes symbols $b_1$ through $b_k$, and directes each head to move left or right, or to stay put, as specified.

<h4 style="color:#FF0266">Theorem 1 : Statement</h4>

Every multitape Turing machine has an equivalent single-tape Turing machine.

<h4 style="color:#FF0266">Theorem 1 : Proof</h4>
We show how to convert a multitape TM $M$ to an equivalent single-tape TM $S$. The key idea is to show how to simulate $M$ with $S$.

Say that $M$ has $k$ tapes. Then $S$ simulates the effect of $k$ tapes by storing their information on its single tape. It uses the new symbol $\#$ as a delimiter to seperate the contents of the different tapes. In addition to the contents of these tapes, $S$ must keep track of the locations of the heads. It does so by writing a symbol with a dot above it to mark the place where the head on that tape would be. The figure 3.14 in page 177 helps illustrate this.

<h4 style="color:#FF0266">Corollary 1</h4>

A language is Turing-recognizable if and only if some multitape Turing machine recognizes it. 

<h4 style="color:#FF0266">Corollary 1 : Proof</h4>

A Turing-recognizable language is recognized by an ordinary (single-tape) Turing machine, which is a special case of a multitape Turing machine. The proves one direction of this corollary. The other direction follows from the previous theorem.


<h3 style="color:#03DAC5">Nondeterministic Turing Machines</h3>

A nondeterministic Turing machine is defined in the expected way. At any point in a computation, the machine may proceed according to several possibilities. The transition function for a nondeterministic Turing machine has the form

$\delta : Q \times \Gamma \rightarrow P(Q \times \Gamma \times \{L, R\})$

<h4 style="color:#FF0266">Theorem 2 : Statement</h4>

Every nondeterministic Turing machine has an equivalent deterministic Turing machine.

<h4 style="color:#FF0266">Theorem 2 : Proof Idea</h4>

We can simulate any nondeterministic TM $N$ with a deterministic TM $D$. The idea behind the simulation is to have $D$ try all possible branches of $N$'s nondeterministic computation. If $D$ ever finds the accept state on one of these branches, $D$ accepts. Otherwise, $D$'s simulation will not terminate.

We view $N$'s computation on an input $w$ as a tree. Each branch of the tree represents one of the branches of the nondeterminism. Each node of the tree represents one of the branches of the nondeterminism. Each node of the tree is a configuration of $N$. The root of the tree is the start configuration. The TM $D$ searches this tree for an accepting configuration. We design $D$ to explore the tree using breadth-first search (not depth-first and I would assume you know why; otherwise, think about it) instead. This strategy explores all branches to the same depth before going on to explore any branch to the next depth. This method guarantees that $D$ will visit every node in the tree until it encounters an accepting configuration.


<h4 style="color:#FF0266">Theorem 2 : Proof</h4>
The simulating deterministic TM $D$ has three tapes. By the previous theorem, this arrangment is equivalent to having a single tape. The machine $D$ uses its three tapes in a particular way. Tape 1 always contains the input string and is never altered. Tape 2 maintains a copy of N's tape on some branch of its nondeterministic computation. Tape 3 keeps track of $D$'s location in $N$'s nondeterministic computation tree.

Let's first consider the data representation on tape 3. Every node in tree can have at most $b$ children, where $b$ is the size of the largest set of possible choices given by $N$'s transition function. To every node in the tree we assign an address that is a string over the alphabet $\Gamma_b = \{1, 2,...,b\}$. We assign the address 231 to the node we arrive at by starting at the root, going to its 2nd child, going to that node's 3rd child, and finally going to that node's 1st child. Each symbol in the string tells us which choice to make next when simulating a step in one branch in $N$'s nondeterministic computation. Sometimes a symbol may not correspond to any choice if too few choices are available for a configuration. In that case, the address is invalid and doesn't correspond to any node. Tape 3 contains a string over $\Gamma_b$. It represents the branch of $N$'s computation from the root to the node addressed by that string unless the address is invalid. The empty string is the address of the root of the tree. Now we are ready to describe $D$.

  1. Initially, tape 1 contains the input $w$, and tapes 2 and 3 are empty.
  2. Copy tape 1 to tape 2 and initialize the string on tape 3 to be $\epsilon$
  3. Use tape 2 to simulate $N$ with input $w$ on one branch of its nondeterministic computation. Before each step of $N$, consult the next symbol on tape 3 to determine which choice to make among those allowed by $N$'s transition function. If no more symbols remain on tape $3$ or if this nondeterministic choice is invalid, abort this branch by going to stage 4. Also go to stage 4 if a rejecting configuration is encountered. If an accepting configuration is encountered, $accept$ the input.
  4. Replace the string on tape 3 with the next string in the string ordering. Simulate the next branch of $N$'s computation by going to stage 2.

In my own words, tape 1 is never touched it's part of the first step of determining what the input is but otherwise it doesn't matter. Tape 2 is a copy of tape 1 thats reset everytime we check a configuration. It's our test input and what we use to check if some configuration is valid. Tape 3 contains all possible configurations we might encounter and thus continuously simulates these configurations on our tape.

<h4 style="color:#FF0266">Corollary 2</h4>

A language is Turing-recognizable if and only if some nondeterministic Turing machine recognizes it.

<h4 style="color:#FF0266">Corollary 2 : Proof</h4>
Any deterministic TM is automatically a nondeterministic TM, and so one direction of this corollary follows immediatly. The other direction follows from the fact that a language is turing-recognizable iff some DTM recognizes it.


<h4 style="color:#FF0266">Corollary 3</h4>

A language is decidable if and only if some nondeterministic Turing machine decides it.

<h3 style="color:#03DAC5">Enumerators</h3>

Loosely defined, an enumerator is a Turing machine with an attached printer. The Turing machine can use that printer as an output device to print strings. Everytime the Turing machine wants to add a string to the list, it sends the string to the printer. We can formally define the enumerator $E = (Q, \Sigma, \Gamma, \delta, q_1, q_{print}, q_{reject})$ such that

* $Q = \{q_1, q_2,...,q_{print}, q_{reject} \}$
* $\Sigma = \text{finite set of ouput/print alphabet}$
* $\Gamma = \text{Finite set of the working tape alphabet}$
* $\delta = \text{Transition Function} Q \times \Gamma \rightarrow Q \times \Gamma \times \{L, R\} \times \Sigma_{\epsilon}$
* $q_1, q_{print}$ and $q_{rejecct}$ are respecitvely the start, print and reject states.
<br>
An enumerator starts with a blank input on its work tape. If the enumerator doesn't halt, it may print an infinite list of strings. The language enumerated by $E$ is the collection of all the strings that it eventually prints out. Moreover, $E$ may generate the strings of the language in any order, possibly with repetitions.

<h4 style="color:#FF0266">Theorem 3 : Statement</h4>

A language is Turing-recognizable if and only if some enumerator enumerates it. 

<h4 style="color:#FF0266">Theorem 3 : Proof</h4>

First we show that if we have an enumerator $E$ that enumerates a language $A$, a TM $M$ recognizes $A$. The TM $M$ works in the following way.

$M$ = "On input $w$:
  1. Run $E$. Every time that $E$ outputs a string, compare it with $w$.
  2. If $w$ ever appears in the output of $E$, $accept$."

Clearly $M$ accepts those strings that appear on $E$'s list.
Now we do the other direction. If TM $M$ recognizes a language $A$, we can construct the following enumerator $E$ for $A$. Say that $s_1, s_2, s_3, ...$ is a list of all possible strings in $\Sigma^*$.

$E$ = " Ignore the input.
  1. Repeat the following for $i = 1,2,3,...$
    2. Run $M$ for $i$ steps on each input, $s_1, s_2,...,s_i$.
    3. If any computations accept, print out the corresponding $s_j$.

If $M$ accepts a particular string $s$, eventually it will appear on the list generated by $E$. In fact, it will appear on the list infinitely many times because $M$ runs from the beginning on each string for each repitition of step 1. This procdure gives the effect of running $M$ in parallel on all possible input strings.

<h3 style="color:#03DAC5">RAM (Random Access Machines)</h3>
<h4 style="color:#FF0266">Commands</h4>

<table>
<tr>
  <td>Command</td>
  <td>Action</td>
</tr>
<tr>
  <th>load i</th>
  <th>a = c(i); k += 1</th>
</tr>
<tr>
  <th>store i</th>
  <th>c(i) = a; k += 1</th>
</tr>
<tr>
  <th>add i</th>
  <th>a = a + c(i); k += 1</th>
</tr>
<tr>
  <th>sub i</th>
  <th>a = max(a - c(i), 0); k += 1</th>
</tr>
<tr>
  <th>read</th>
  <th>a = $x_{hr}; h_r = h_r + 1$; k += 1</th>
</tr>
<tr>
  <th>print a</th>
  <th>y = ay; k += 1</th>
</tr>
<tr>
  <th>print a</th>
  <th>y = ay; k += 1</th>
</tr>
<tr>
  <th>shift</th>
  <th>SEE *</th>
</tr>
<tr>
  <th>goto i</th>
  <th>k = i (i > 0)</th>
</tr>
<tr>
  <th>if a=i goto j</th>
  <th>a=i ? k = j : k += 1</th>
</tr>
</table>

<h4 style="color:#FF0266">Theorem 4 : Statement</h4>
Let $M$ be a single tape machine, there exists a RAM which terminates and outputs 1 whevener M accepts $w$ and outputs 0 whenever M rejects $w$.

<h4 style="color:#FF0266">Theorem 5 : Statement</h4>
Let $R$ be a random access machine with a fixed given program. For an aribitrary given input $x \in \Sigma^*$ it is assumed to compute an output $y(x) \in \Sigma^*$. There exists a multi-tape Turing machine that accepts the input $x \in \Sigma^*$ after writing $y(x) \in \Sigma^*$ on one of its tapes.

<h4 style="color:#FF0266">Theorem 5 : Statement</h4>
Turing machines and random access machines have the same amount of expressive power.
